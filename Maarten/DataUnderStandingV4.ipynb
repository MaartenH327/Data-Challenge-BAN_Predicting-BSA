{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TrainModel as Train\n",
    "import PredictData as Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import umap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "def CheckNan(df):\n",
    "    nan_columns = df.isna().sum()\n",
    "\n",
    "    if len(nan_columns[nan_columns> 0]) >0:\n",
    "        print(f\"{len(df)} students\")\n",
    "        raise ValueError(f\"These columns contain NaN values this is not going work! \\n {nan_columns[nan_columns> 0]}\")\n",
    "    \n",
    "    print(f\"All good\")\n",
    "    return\n",
    "\n",
    "    \n",
    "def RemoveEntries(df):\n",
    "\n",
    "    df2 = df\n",
    "\n",
    "    _base = len(df)\n",
    "    print()\n",
    "    #df = df[df[\"Credits-Y1\"] > 0].reset_index(drop=True)\n",
    "    df = df.dropna(subset=[\"OverAll\"]).reset_index(drop=True)\n",
    "    df = df.dropna(subset=[\"B1B2\"]).reset_index(drop=True)\n",
    "    \n",
    "\n",
    "        \n",
    "    diff_df = df2.merge(df,on=list(df2.columns), how = 'left', indicator=True)\n",
    "    missing_rows_df = diff_df[diff_df[\"_merge\"] == \"left_only\"].drop(columns=[\"_merge\"])\n",
    "\n",
    "    print(f\"Started with {_base} students\")\n",
    "    print(f\"dropped {_base-len(df)} students\")\n",
    "    print(missing_rows_df[\"BSA\"].value_counts())\n",
    "    print(f\"\\n =======Remaining========= \\n {len(df)}\")\n",
    "    print(df[\"BSA\"].value_counts())\n",
    "    return df\n",
    "\n",
    "\n",
    "def TheQuiters(merged_df):\n",
    "    columns_to_check = [col for col in merged_df.columns if col.startswith(\"x_Course\") and col.endswith(\"Both_notPresent\")]\n",
    "\n",
    "    rows_to_remove = merged_df[merged_df[columns_to_check].sum(axis=1) >= 3].index\n",
    "    print(len(rows_to_remove))\n",
    "    merged_df = merged_df.drop(rows_to_remove)\n",
    "    return merged_df\n",
    "\n",
    "def PrepCluster(df, UseNationalities= False, UsePreEducation =True):\n",
    "    df['Gender'] = df['Gender'].apply(lambda x: 1 if x == 'F' else 0)\n",
    "\n",
    "    columns_to_drop = ['train', 'Year', 'BSA', 'Crd-B1B2', \"Program\"]\n",
    "\n",
    "    df_Clustering = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    #Make Nationalities dummies\n",
    "    if UseNationalities:\n",
    "        #Create dummy variables\n",
    "        nationality_dummies = pd.get_dummies(df_Clustering['Nationality'], prefix='Nationality',dtype='int')\n",
    "\n",
    "        if \"Nationality_Niet toeg. Nationaliteit(n/e)\" in nationality_dummies.columns:\n",
    "            nationality_dummies = nationality_dummies.drop([\"Nationality_Niet toeg. Nationaliteit(n/e)\"], axis=1)\n",
    "            print('Dropped Nationalities')\n",
    "            \n",
    "        # Concatenate the dummy variables with the original DataFrame\n",
    "        df_Clustering = pd.concat([df_Clustering, nationality_dummies], axis=1)\n",
    "\n",
    "        Nationalities= ['Nationality_Afrika', 'Nationality_Azie', 'Nationality_EU',\n",
    "        'Nationality_Europa', 'Nationality_Mid-Zuid-Amerika',\n",
    "        'Nationality_Nederland', 'Nationality_Noord-Amerika',\n",
    "        'Nationality_Oceanie', 'Nationality_Onbekend']\n",
    "\n",
    "        for col_name in Nationalities:\n",
    "            if col_name not in df_Clustering:\n",
    "                df_Clustering[col_name] = 0\n",
    "\n",
    "    if UsePreEducation:\n",
    "        #Create dummy variables\n",
    "        preEducation_dummies = pd.get_dummies(df_Clustering['PreEducation'], prefix='PreEducation',dtype='int')\n",
    "\n",
    "        if \"PreEducation_nvt\" in preEducation_dummies.columns:\n",
    "            preEducation_dummies = preEducation_dummies.drop([\"PreEducation_nvt\"], axis=1)\n",
    "            print('Dropped PreEducation_Overig')\n",
    "            \n",
    "        if \"PreEducation_Overig\" in preEducation_dummies.columns:\n",
    "            preEducation_dummies = preEducation_dummies.drop([\"PreEducation_Overig\"], axis=1)\n",
    "            print('PreEducation_Overig')\n",
    "\n",
    "        if \"PreEducation_Wo\" in preEducation_dummies.columns:\n",
    "            preEducation_dummies = preEducation_dummies.drop([\"PreEducation_Wo\"], axis=1)\n",
    "            print('PreEducation_Wo')         \n",
    "\n",
    "        # Concatenate the dummy variables with the original DataFrame\n",
    "        df_Clustering = pd.concat([df_Clustering, preEducation_dummies], axis=1)\n",
    "\n",
    "        preEducations= ['PreEducation_Buitenlands', 'PreEducation_Hbo', 'PreEducation_Vwo']\n",
    "\n",
    "        for col_name in preEducations:\n",
    "            if col_name not in df_Clustering:\n",
    "                df_Clustering[col_name] = 0\n",
    "                \n",
    " \n",
    "    # Drop the original 'Nationality' column\n",
    "    df_Clustering = df_Clustering.drop(columns=[\"Nationality\",\"PreEducation\"])\n",
    "\n",
    "    return df_Clustering\n",
    "\n",
    "\n",
    "def PrepB1B2(df):\n",
    "        # Assuming df is your DataFrame\n",
    "    columns_to_drop = [col for col in df.columns if col.startswith((\"3\",\"4\",\"5\",\"6\"))] + [\"TheRest\",\"OverAll\"] + [col for col in df.columns if (col.startswith((\"2\")) and col.endswith(\"Endgrade\") )]+ [col for col in df.columns if (\"grade\" in col.lower() )]\n",
    "    #columns_to_drop += [col for col in df.columns if col.startswith(\"2\")]  \n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(f'PrepareDatasets/Train_Program3_21_22.xlsx', sheet_name=0)\n",
    "df = RemoveEntries(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"BSA\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluser = PrepCluster(df)\n",
    "df_cluser = PrepB1B2(df_cluser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CheckNan(df_cluser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluser[\"BSA\"] = (df_cluser[\"Credits-Y1\"] > 42).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score,recall_score, f1_score\n",
    "import umap\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluser.drop([\"Credits-Y1\",\"Gender\", 'PreEducation_Buitenlands',\n",
    "       'PreEducation_Hbo', 'PreEducation_Vwo'] + [col for col in df_cluser.columns if col.endswith(\"_standardized\")], axis=1).dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP()\n",
    "umap_embeddings_DESC = reducer.fit_transform(df_cluser.drop([\"Credits-Y1\",\"Gender\", 'PreEducation_Buitenlands',\n",
    "       'PreEducation_Hbo', 'PreEducation_Vwo'] + [col for col in df_cluser.columns if col.endswith(\"_standardized\")], axis=1).dropna().reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot2(df,cluster_labels,umap_embeddings,  ConfusionMatrix = True, color_dict= {}):\n",
    "\n",
    "    hover_columns = ['Credits-Y1', \"Gender\", 'Nationality',\"Crd-B1B2\" ,\"PreEducation\",\"train\", \"BSA\", \"B1B2\",\"TheRest\",\"OverAll\"] # \n",
    "\n",
    "    # Create hover text by concatenating values from specified columns\n",
    "    hover_text = df.apply(lambda row: '<br>'.join(f\"{col}: {row[col]}\" for col in hover_columns), axis=1)\n",
    "    len(hover_text)\n",
    "    # Define marker symbols based on BSA values\n",
    "    marker_symbols = ['square' if bsa == \"PS\" else 'cross' for bsa in df['BSA']]\n",
    "\n",
    "    # marker_symbols[df[df[\"train\"] == 20001521].index[0]] = \"pentagon\" \n",
    "    # marker_symbols[df[df[\"train\"] == 20001585].index[0]] = \"pentagon\" \n",
    "\n",
    "    colors = cluster_labels.map(color_dict)\n",
    "\n",
    "    # Create a scatter plot trace with hover data\n",
    "    scatter_trace = go.Scatter(\n",
    "        x=umap_embeddings[:, 0],\n",
    "        y=umap_embeddings[:, 1],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            color=colors,\n",
    "            size=10,\n",
    "            symbol=marker_symbols,  # Set the marker symbols\n",
    "            colorbar=dict(title='Cluster')\n",
    "        ),\n",
    "        text=hover_text  # Set the hover text\n",
    "    )\n",
    "\n",
    "    # Create a layout\n",
    "    layout = go.Layout(\n",
    "        title='UMAP 2-D representation of document embeddings with K-Means clustering',\n",
    "        xaxis=dict(title='UMAP Dimension 1'),\n",
    "        yaxis=dict(title='UMAP Dimension 2'),\n",
    "        width=1600,  # Set width of the figure\n",
    "        height=1200,  # Set height of the figure\n",
    "\n",
    "    )\n",
    "\n",
    "    # Create a figure\n",
    "    fig = go.Figure(data=[scatter_trace], layout=layout)\n",
    "\n",
    "    # Show the interactive plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(2)\n",
    "kmeans.fit(df_cluser.drop([\"Credits-Y1\",\"Gender\", 'PreEducation_Buitenlands',\n",
    "       'PreEducation_Hbo', 'PreEducation_Vwo'] + [col for col in df_cluser.columns if col.endswith(\"_standardized\")], axis=1).dropna().reset_index(drop=True))\n",
    "print(type(kmeans.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot2(\n",
    "#     df,\n",
    "#     pd.Series(kmeans.labels_),\n",
    "#     umap_embeddings_DESC,\n",
    "#     False,\n",
    "#     {30: \"Purple\",\n",
    "# 24:\"Green\",\n",
    "# 18:\"LightGreen\",\n",
    "# 2:\"Green\",\n",
    "# 1:\"LightGreen\",\n",
    "# 0:\"blue\"}\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "Plot2(\n",
    "    df,\n",
    "    df[\"Crd-B1B2\"],\n",
    "    umap_embeddings_DESC,\n",
    "    False,\n",
    "    {30: \"Purple\",\n",
    "24:\"Green\",\n",
    "18:\"LightGreen\",\n",
    "12:\"Orange\",\n",
    "6:\"Red\",\n",
    "0:\"Black\"}\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
