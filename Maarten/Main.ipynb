{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TrainModel as Train\n",
    "import PredictData as Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import umap\n",
    "from sklearn.metrics import confusion_matrix, precision_score,recall_score, f1_score, accuracy_score\n",
    "import umap\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "def CheckNan(df):\n",
    "    nan_columns = df.isna().sum()\n",
    "\n",
    "    if len(nan_columns[nan_columns> 0]) >0:\n",
    "        print(f\"{len(df)} students\")\n",
    "        raise ValueError(f\"These columns contain NaN values this is not going work! \\n {nan_columns[nan_columns> 0]}\")\n",
    "    \n",
    "    #print(f\"All good\")\n",
    "    \n",
    "\n",
    "    \n",
    "def RemoveEntries(df):\n",
    "\n",
    "    df2 = df\n",
    "\n",
    "    _base = len(df)\n",
    "\n",
    "    #df = df[df[\"Credits-Y1\"] > 0].reset_index(drop=True)\n",
    "    df = df.dropna(subset=[\"OverAll\"]).reset_index(drop=True)\n",
    "    df = df.dropna(subset=[\"B1B2\"]).reset_index(drop=True)\n",
    "    df = df.dropna(subset=[\"TheRest\"]).reset_index(drop=True)   \n",
    "\n",
    "    df = df.dropna(subset=[\"TheRest\"]).reset_index(drop=True)   \n",
    "\n",
    "    diff_df = df2.merge(df,on=list(df2.columns), how = 'left', indicator=True)\n",
    "    missing_rows_df = diff_df[diff_df[\"_merge\"] == \"left_only\"].drop(columns=[\"_merge\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # print(f\"Started with {_base} students\")\n",
    "    # print(f\"dropped {_base-len(df)} students\")\n",
    "    # print(missing_rows_df[\"BSA\"].value_counts())\n",
    "    # print(f\"\\n =======Remaining========= \\n {len(df)}\")\n",
    "    # print(df[\"BSA\"].value_counts())\n",
    "    return df\n",
    "\n",
    "\n",
    "def RemoveEntries2(df):\n",
    "\n",
    "    df2 = df\n",
    "\n",
    "    _base = len(df)\n",
    "\n",
    "    df = df[df[\"BSA\"].isin([\"PS\",\"NE\"])].reset_index(drop=True)\n",
    "        \n",
    "    diff_df = df2.merge(df,on=list(df2.columns), how = 'left', indicator=True)\n",
    "    missing_rows_df = diff_df[diff_df[\"_merge\"] == \"left_only\"].drop(columns=[\"_merge\"])\n",
    "\n",
    "    # print(f\"Started with {_base} students\")\n",
    "    # print(f\"dropped {_base-len(df)} students\")\n",
    "    # print(missing_rows_df[\"BSA\"].value_counts())\n",
    "    # print(f\"\\n =======Remaining========= \\n {len(df)}\")\n",
    "    # print(df[\"BSA\"].value_counts())\n",
    "    return df\n",
    "\n",
    "\n",
    "def DropQuiters(merged_df):\n",
    "    columns_to_check = [col for col in merged_df.columns if col.startswith((\"4\",\"5\",\"6\")) and col.endswith(\"Both_notPresent\")]\n",
    "\n",
    "    rows_to_remove = merged_df[merged_df[columns_to_check].sum(axis=1) >= 3].index\n",
    "    print(len(rows_to_remove))\n",
    "    merged_df = merged_df.drop(rows_to_remove)\n",
    "    return merged_df\n",
    "\n",
    "def PrepCluster(df, UseNationalities= False, UsePreEducation =True):\n",
    "    columns_to_drop = []\n",
    "\n",
    "    columns_to_drop += [col for col in df.columns if col in ['train', 'Year', 'BSA', \"Program\"]]\n",
    "\n",
    "\n",
    "    df_Clustering = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    #Make Nationalities dummies\n",
    "    if UseNationalities:\n",
    "        #Create dummy variables\n",
    "        nationality_dummies = pd.get_dummies(df_Clustering['Nationality'], prefix='Nationality',dtype='int')\n",
    "\n",
    "        if \"Nationality_Niet toeg. Nationaliteit(n/e)\" in nationality_dummies.columns:\n",
    "            nationality_dummies = nationality_dummies.drop([\"Nationality_Niet toeg. Nationaliteit(n/e)\"], axis=1)\n",
    "            print('Dropped Nationalities')\n",
    "            \n",
    "        # Concatenate the dummy variables with the original DataFrame\n",
    "        df_Clustering = pd.concat([df_Clustering, nationality_dummies], axis=1)\n",
    "\n",
    "        Nationalities= ['Nationality_Afrika', 'Nationality_Azie', 'Nationality_EU',\n",
    "        'Nationality_Europa', 'Nationality_Mid-Zuid-Amerika',\n",
    "        'Nationality_Nederland', 'Nationality_Noord-Amerika',\n",
    "        'Nationality_Oceanie', 'Nationality_Onbekend']\n",
    "\n",
    "        for col_name in Nationalities:\n",
    "            if col_name not in df_Clustering:\n",
    "                df_Clustering[col_name] = 0\n",
    "\n",
    "    if UsePreEducation:\n",
    "        #Create dummy variables\n",
    "        preEducation_dummies = pd.get_dummies(df_Clustering['PreEducation'], prefix='PreEducation',dtype='int')\n",
    "\n",
    "        if \"PreEducation_nvt\" in preEducation_dummies.columns:\n",
    "            preEducation_dummies = preEducation_dummies.drop([\"PreEducation_nvt\"], axis=1)\n",
    "            #print('Dropped PreEducation_Overig')\n",
    "            \n",
    "        if \"PreEducation_Overig\" in preEducation_dummies.columns:\n",
    "            preEducation_dummies = preEducation_dummies.drop([\"PreEducation_Overig\"], axis=1)\n",
    "            #print('PreEducation_Overig')\n",
    "\n",
    "        if \"PreEducation_Wo\" in preEducation_dummies.columns:\n",
    "            preEducation_dummies = preEducation_dummies.drop([\"PreEducation_Wo\"], axis=1)\n",
    "            #print('PreEducation_Wo')         \n",
    "\n",
    "        # Concatenate the dummy variables with the original DataFrame\n",
    "        df_Clustering = pd.concat([df_Clustering, preEducation_dummies], axis=1)\n",
    "\n",
    "        preEducations= ['PreEducation_Buitenlands', 'PreEducation_Hbo', 'PreEducation_Vwo']\n",
    "\n",
    "        for col_name in preEducations:\n",
    "            if col_name not in df_Clustering:\n",
    "                df_Clustering[col_name] = 0\n",
    "\n",
    "        df_Clustering = df_Clustering[sorted(df_Clustering.columns.difference(preEducations)) + preEducations]\n",
    "\n",
    " \n",
    "    # Drop the original 'Nationality' column\n",
    "    df_Clustering = df_Clustering.drop(columns=[\"Nationality\",\"PreEducation\"])\n",
    "\n",
    "    return df_Clustering\n",
    "\n",
    "def DropGrades(df):\n",
    "     # Assuming df is your DataFrame\n",
    "    columns_to_drop = []\n",
    "    columns_to_drop += [col for col in df.columns if (\"grade\" in col.lower() )]  \n",
    "    #columns_to_drop += [col for col in df.columns if col.startswith(\"2\")]  \n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    return df\n",
    "\n",
    "def PrepB1B2(df):\n",
    "     # Assuming df is your DataFrame\n",
    "    columns_to_drop =  [col for col in df.columns if col.startswith((\"3\",\"4\",\"5\",\"6\"))] \n",
    "    columns_to_drop += [col for col in df.columns if col in [\"TheRest\",\"OverAll\"]]\n",
    "    columns_to_drop += [col for col in df.columns if (col.startswith((\"2\")) and col.endswith(\"Endgrade\") )]\n",
    "    columns_to_drop += [col for col in df.columns if (\"grade\" in col.lower() )]\n",
    "    columns_to_drop += [col for col in df.columns if (col.startswith((\"2\")) and col.endswith(\"PassedCourse\") )]\n",
    "    columns_to_drop += [col for col in df.columns if (col.startswith((\"2\")) and col.endswith(\"Both_notPresent\") )]\n",
    "\n",
    "    \n",
    "    #columns_to_drop += [col for col in df.columns if col.startswith(\"2\")]  \n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    return df\n",
    "\n",
    "\n",
    "def MakeSimple(df):\n",
    "     # Assuming df is your DataFrame\n",
    "    columns_to_drop = []\n",
    "    columns_to_drop += [col for col in df.columns if (col.startswith((\"1\")) and col.endswith(\"FirstTryPassed\") )]\n",
    "    columns_to_drop += [col for col in df.columns if (col.startswith((\"1\")) and col.endswith(\"FirstTryPresent\") )]\n",
    "    columns_to_drop += [col for col in df.columns if (col.startswith((\"1\")) and col.endswith(\"Both_notPresent\") )]\n",
    "    \n",
    "    columns_to_drop += [col for col in df.columns if (col.startswith((\"2\")) and col.endswith(\"FirstTryPresent\") )]\n",
    "    \n",
    "    #columns_to_drop += [col for col in df.columns if col.startswith(\"2\")]  \n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    return df\n",
    "\n",
    "def MakeRoel(df):\n",
    "     # Assuming df is your DataFrame\n",
    "    columns_to_drop = []\n",
    "    columns_to_drop += [col for col in df.columns if col.endswith(\"FirstTryPassed\")]\n",
    "    columns_to_drop += [col for col in df.columns if col.endswith(\"FirstTryPresent\")]\n",
    "    columns_to_drop += [col for col in df.columns if col.endswith(\"PassedCourse\")]   \n",
    "    columns_to_drop += [col for col in df.columns if (col.startswith((\"1\")) and col.endswith(\"Both_notPresent\") )]\n",
    "    \n",
    "    columns_to_drop += [col for col in df.columns if (col.startswith((\"2\")) and col.endswith(\"FirstTryPresent\") )]\n",
    "\n",
    "    #columns_to_drop += [col for col in df.columns if col.startswith(\"2\")]  \n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    return df\n",
    "\n",
    "def MakeRoelV2(df):\n",
    "     # Assuming df is your DataFrame\n",
    "    columns_to_drop = []\n",
    "    columns_to_drop += [col for col in df.columns if col.endswith(\"FirstTryPassed\")]\n",
    "    columns_to_drop += [col for col in df.columns if col.endswith(\"FirstTryPresent\")]\n",
    "    columns_to_drop += [col for col in df.columns if col.endswith(\"PassedCourse\")]   \n",
    "    columns_to_drop += [col for col in df.columns if (col.startswith((\"1\")) and col.endswith(\"Both_notPresent\") )]\n",
    "    \n",
    "    columns_to_drop += [col for col in df.columns if (col.startswith((\"2\")) and col.endswith(\"FirstTryPresent\") )]\n",
    "\n",
    "\n",
    "    columns_to_drop += [col for col in df.columns if (col.startswith((\"2\")) and col.endswith(\"FirstTryPresent\") )]\n",
    "    columns_to_drop += [col for col in df.columns if (col.startswith((\"2\")) and col.endswith(\"FirstTryPresent\") )]\n",
    "\n",
    "    columns_to_drop += [col for col in df.columns if (col.startswith((\"PreEducation\")))]\n",
    "    columns_to_drop += [col for col in df.columns if (col.startswith((\"Roel_Resit_Factor\")))]\n",
    "\n",
    "    columns_to_drop += [col for col in df.columns if (col.startswith((\"Roel_Resit_Factor\")))]\n",
    "    #columns_to_drop += [col for col in df.columns if col.startswith(\"2\")]  \n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def RemoveRoel(df):\n",
    "    columns_to_drop = []\n",
    "    columns_to_drop += [col for col in df.columns if col.endswith(\"Roel_Resit_Factor\")]\n",
    "    columns_to_drop += [col for col in df.columns if col.endswith(\"Total_absent\")]\n",
    "    #columns_to_drop += [col for col in df.columns if col.startswith(\"2\")]  \n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Model:\n",
    "    name: str\n",
    "    modelMode: str\n",
    "    preprocessingMode: str\n",
    "    smoteMode: str\n",
    "\n",
    "    traindata: pd.DataFrame\n",
    "    train: Callable[[pd.DataFrame, bool],Train.TrainedModel] = field(init=False,repr=False)\n",
    "    trainedmodel: Train.TrainedModel\n",
    "\n",
    "    def __init__(self,modelMode,preprocessingMode,smoteMode,traindata,trainmethod) -> None:\n",
    "\n",
    "        self.modelMode = modelMode\n",
    "        self.preprocessingMode = preprocessingMode\n",
    "        self.smoteMode = smoteMode\n",
    "\n",
    "        self.traindata = traindata\n",
    "        self.train = trainmethod\n",
    "\n",
    "        self.name = preprocessingMode + \"_\" + modelMode + \"_\" + smoteMode \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTheModels(modelList: List[Model],df_cluster,preproName,smoteName):\n",
    "    print(f\"GetTheModels\")\n",
    "\n",
    "    svm = Model(\"SVM\",preproName,smoteName,PrepB1B2(df_cluster),Train.SVM_Default)\n",
    "    svm.trainedmodel = svm.train(svm.traindata,False)\n",
    "    modelList.append(svm)\n",
    "    print(f\"SVM \")\n",
    "\n",
    "    nnA = Model(\"NN\",preproName,smoteName,PrepB1B2(df_cluster),Train.NeuralNetwork_Default)\n",
    "    nnA.trainedmodel = nnA.train(nnA.traindata,False)\n",
    "    modelList.append(nnA)\n",
    "    print(f\"NN \")\n",
    "    # xgA = Model(\"xG\",preproName,smoteName,PrepB1B2(df_cluster),Train.XgBoost)\n",
    "    # xgA.trainedmodel = xgA.train(xgA.traindata,False)\n",
    "    # modelList.append(xgA)\n",
    "    # print(f\"xG \")\n",
    "\n",
    "\n",
    "    rF = Model(\"rF\",preproName,smoteName,PrepB1B2(df_cluster),Train.RandomForest)\n",
    "    rF.trainedmodel = rF.train(rF.traindata,False)\n",
    "    modelList.append(rF)\n",
    "    print(f\"rF \")\n",
    "\n",
    "    # GBM = Model(\"GBM\",preproName,smoteName,PrepB1B2(df_cluster),Train.GBM)\n",
    "    # GBM.trainedmodel = GBM.train(GBM.traindata,False)\n",
    "    # modelList.append(GBM)\n",
    "    # print(f\"GBM\")\n",
    "\n",
    "\n",
    "    KNeighbor = Model(\"KNeighbor\",preproName,smoteName,PrepB1B2(df_cluster),Train.KNeighbor)\n",
    "    KNeighbor.trainedmodel = KNeighbor.train(KNeighbor.traindata,False)\n",
    "    modelList.append(KNeighbor)\n",
    "    print(f\"KNeighbor\")\n",
    "\n",
    "    NaiveBayes = Model(\"NaiveBayes\",preproName,smoteName,PrepB1B2(df_cluster),Train.NaiveBayes)\n",
    "    NaiveBayes.trainedmodel = NaiveBayes.train(NaiveBayes.traindata,False)\n",
    "    modelList.append(NaiveBayes)\n",
    "    print(f\"NaiveBayes\")\n",
    "\n",
    "    LRegression = Model(\"LRegression\",preproName,smoteName,PrepB1B2(df_cluster),Train.LRegression)\n",
    "    LRegression.trainedmodel = LRegression.train(LRegression.traindata,False)\n",
    "    modelList.append(LRegression)\n",
    "    print(f\"LRegression\")\n",
    "\n",
    "    # decisionTreeClassifier = Model(\"Tree\",preproName,smoteName,PrepB1B2(df_cluster),Train.decisionTreeClassifier)\n",
    "    # decisionTreeClassifier.trainedmodel = decisionTreeClassifier.train(decisionTreeClassifier.traindata,False)\n",
    "    # modelList.append(decisionTreeClassifier)\n",
    "    # print(f\"decisionTreeClassifier\")\n",
    "\n",
    "    \n",
    "    # lgbBig = Model(\"lgbBig\",preproName,smoteName,PrepB1B2(df_cluster),Train.lgbBig)\n",
    "    # lgbBig.trainedmodel = lgbBig.train(lgbBig.traindata,False)\n",
    "    # modelList.append(lgbBig)\n",
    "    # print(f\"lgbBig\")\n",
    "\n",
    "\n",
    "    return modelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(i):\n",
    "    print(f\"Program {i}\")\n",
    "    df = pd.concat([\n",
    "        pd.read_excel(f'PrepareDatasets/Train_Program{i}_22_23.xlsx', sheet_name=0),\n",
    "        pd.read_excel(f'PrepareDatasets/Train_Program{i}_21_22.xlsx', sheet_name=0),\n",
    "        ],ignore_index=True)\n",
    "\n",
    "    df = RemoveEntries(df)\n",
    "    df['Gender'] = df['Gender'].apply(lambda x: 1 if x == 'F' else 0)\n",
    "\n",
    "    \n",
    "    modelList: List[Model] = []\n",
    "\n",
    "\n",
    "    dfTrueBSA = RemoveEntries2(df)\n",
    "    dfTrueBSA_cluser = PrepCluster(dfTrueBSA)\n",
    "    dfTrueBSA_cluser = DropGrades(dfTrueBSA_cluser)\n",
    "    CheckNan(dfTrueBSA_cluser)\n",
    "    dfTrueBSA_cluser[\"BSA\"] = (dfTrueBSA_cluser[\"Credits-Y1\"] > 42).astype(int)\n",
    "    dfTrueBSA_cluser = RemoveRoel(dfTrueBSA_cluser)   \n",
    "\n",
    "    GetTheModels(modelList,dfTrueBSA_cluser,\"High\",\"False\")\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        dfTrueBSA_cluser_smoteB1B2 = SmoteB1B2(dfTrueBSA_cluser)\n",
    "        GetTheModels(modelList,dfTrueBSA_cluser_smoteB1B2,\"High\",\"True\")  \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # try:\n",
    "    #     dfTrueBSA_cluser_smoteB1B2 = SmoteSmart(dfTrueBSA_cluser)\n",
    "    #     GetTheModels(modelList,dfTrueBSA_cluser_smoteB1B2,\"High\",\"SmoteSmart\")  \n",
    "    # except:\n",
    "    #     pass\n",
    "\n",
    "\n",
    "\n",
    "    #simple\n",
    "    dfSimple = RemoveEntries2(df)\n",
    "    dfSimple_cluser = PrepCluster(dfSimple)\n",
    "    dfSimple_cluser = DropGrades(dfSimple_cluser)\n",
    "    CheckNan(dfSimple_cluser)\n",
    "    dfSimple_cluser[\"BSA\"] = (dfSimple_cluser[\"Credits-Y1\"] > 42).astype(int)\n",
    "    dfSimple_cluser = MakeSimple(dfSimple_cluser)\n",
    "\n",
    "    GetTheModels(modelList,dfSimple_cluser,\"Medium\",\"False\") \n",
    "\n",
    "\n",
    "    try:\n",
    "        dfSimple_cluser_smoteB1B2 = SmoteB1B2(dfSimple_cluser)\n",
    "        GetTheModels(modelList,dfSimple_cluser_smoteB1B2,\"Medium\",\"True\")   \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Roel\n",
    "    dfRoel_cluser = PrepCluster(RemoveEntries2(df))\n",
    "    dfRoel_cluser = DropGrades(dfRoel_cluser)\n",
    "    CheckNan(dfRoel_cluser)\n",
    "    dfRoel_cluser[\"BSA\"] = (dfRoel_cluser[\"Credits-Y1\"] > 42).astype(int)\n",
    "    dfRoel_cluser = MakeSimple(dfRoel_cluser)\n",
    "    dfRoel_cluser = MakeRoel(dfRoel_cluser)\n",
    "    GetTheModels(modelList,dfRoel_cluser,\"Low\",\"False\")  \n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        dfRoel_cluser_smoteB1B2 = SmoteB1B2Credits(dfRoel_cluser)\n",
    "        GetTheModels(modelList,dfRoel_cluser_smoteB1B2,\"Low\",\"True\")    \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    dfRoel_cluserV2 = MakeRoelV2(dfRoel_cluser)\n",
    "    GetTheModels(modelList,dfRoel_cluserV2,\"Roel\",\"False\")  \n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        dfRoel_cluser_smoteB1B2 = SmoteB1B2Credits(dfRoel_cluserV2)\n",
    "        GetTheModels(modelList,dfRoel_cluser_smoteB1B2,\"Roel\",\"True\")    \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df_test = pd.concat([\n",
    "    pd.read_excel(f'PrepareDatasets/Test_Program{i}_21_22.xlsx', sheet_name=0),\n",
    "    pd.read_excel(f'PrepareDatasets/Test_Program{i}_22_23.xlsx', sheet_name=0),   \n",
    "     ],ignore_index=True)\n",
    "    df_test['Gender'] = df_test['Gender'].apply(lambda x: 1 if x == 'F' else 0)\n",
    "\n",
    "\n",
    "\n",
    "    df_test_cluser = PrepCluster(df_test)\n",
    "    df_test_cluser = PrepB1B2(df_test_cluser)\n",
    "    df_test_cluser[\"BSA\"] = (df_test_cluser[\"Credits-Y1\"] >= 42).astype(int)\n",
    "    df_test = Predict.PrepareDF(df_test)\n",
    "    Predict.AddDefaultRuleToDF(df_test)\n",
    "\n",
    "\n",
    "    for model in modelList:\n",
    "        Predict.AddModelToDF(model.trainedmodel,model.name,df_test,df_test_cluser)\n",
    "\n",
    "    \n",
    "\n",
    "    df2324 = pd.read_excel(f'PrepareDatasets/Pred_Program{i}_23_24.xlsx', sheet_name=0)\n",
    "    df2324['Gender'] = df2324['Gender'].apply(lambda x: 1 if x == 'F' else 0)\n",
    "    df2324_cluser = PrepCluster(df2324)\n",
    "    df2324_cluser = PrepB1B2(df2324_cluser)\n",
    "\n",
    "    df2324 = Predict.PrepareDF(df2324)\n",
    "    Predict.AddDefaultRuleToDF(df2324)\n",
    "\n",
    "\n",
    "    for model in modelList:\n",
    "        Predict.AddModelToDF(model.trainedmodel,model.name,df2324,df2324_cluser)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    return df_test, df2324"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE\n",
    "\n",
    "def Smote(df_cluser):\n",
    "    smote = SMOTE()\n",
    "\n",
    "    X_resampled, y_resampled = smote.fit_resample(df_cluser.drop(columns=[\"Credits-Y1\", \"BSA\"]),df_cluser[\"Credits-Y1\"])\n",
    "\n",
    "    df_cluser_smote = pd.DataFrame(X_resampled)\n",
    "    df_cluser_smote[\"Credits-Y1\"] = y_resampled\n",
    "    df_cluser_smote[\"BSA\"] = df_cluser_smote[\"Credits-Y1\"] >= 42#y_resampled\n",
    "    df_cluser_smote = df_cluser_smote.astype(int)\n",
    "\n",
    "\n",
    "\n",
    "    return df_cluser_smote\n",
    "\n",
    "\n",
    "def SmoteB1B2(df_cluser):\n",
    "\n",
    "    smote = SMOTE()\n",
    "\n",
    "    X_resampled, y_resampled = smote.fit_resample(df_cluser.drop(columns=[\"Credits-Y1\", \"BSA\",\"Crd-B1B2\"]),df_cluser[\"Crd-B1B2\"])\n",
    "\n",
    "    df_cluser_smote = pd.DataFrame(X_resampled)\n",
    "\n",
    "\n",
    "    df_cluser_smote[\"Crd-B1B2\"] = y_resampled\n",
    "    \n",
    "    passed_course_columns = [col for col in df_cluser_smote.columns if col.endswith(\"PassedCourse\")]\n",
    "\n",
    "    passed_course_df = df_cluser_smote[passed_course_columns]\n",
    "\n",
    "    df_cluser_smote[\"Credits-Y1\"] = passed_course_df.sum(axis=1) * 6\n",
    "    df_cluser_smote[\"BSA\"] = df_cluser_smote[\"Credits-Y1\"] >= 42#y_resampled\n",
    "    df_cluser_smote = df_cluser_smote.astype(int)\n",
    "    return df_cluser_smote\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def SmoteB1B2Credits(df_cluser):\n",
    "    smote = SMOTE()\n",
    "\n",
    "    X_resampled, y_resampled = smote.fit_resample(df_cluser.drop(columns=[\"BSA\"]),df_cluser[\"Crd-B1B2\"])\n",
    "\n",
    "    df_cluser_smote = pd.DataFrame(X_resampled)\n",
    "    df_cluser_smote[\"BSA\"] = df_cluser_smote[\"Credits-Y1\"] >= 42#y_resampled\n",
    "    df_cluser_smote = df_cluser_smote.astype(int)\n",
    "\n",
    "    return df_cluser_smote\n",
    "\n",
    "\n",
    "\n",
    "def SmoteSmart(df_cluser):\n",
    "\n",
    "    smote = SMOTE()\n",
    "\n",
    "    df_cluser[\"MinortiyClass\"] = df_cluser[\"Crd-B1B2\"].apply(lambda x: 1 if x == 12 else 0)\n",
    "\n",
    "    X_resampled, y_resampled = smote.fit_resample(df_cluser.drop(columns=[\"Credits-Y1\", \"BSA\",\"MinortiyClass\"]),df_cluser[\"MinortiyClass\"])\n",
    "\n",
    "    df_cluser_smote = pd.DataFrame(X_resampled)\n",
    "\n",
    "\n",
    "    #df_cluser_smote[\"Crd-B1B2\"] = y_resampled\n",
    "    \n",
    "    passed_course_columns = [col for col in df_cluser_smote.columns if col.endswith(\"PassedCourse\")]\n",
    "\n",
    "    passed_course_df = df_cluser_smote[passed_course_columns]\n",
    "\n",
    "    df_cluser_smote[\"Credits-Y1\"] = passed_course_df.sum(axis=1) * 6\n",
    "    df_cluser_smote[\"BSA\"] = df_cluser_smote[\"Credits-Y1\"] >= 42#y_resampled\n",
    "    df_cluser_smote = df_cluser_smote.astype(int)\n",
    "    return df_cluser_smote\n",
    "\n",
    "\n",
    "\n",
    "# def ADASYNB1B2(df_cluser):\n",
    "\n",
    "#     smote = ADASYN()\n",
    "\n",
    "#     X_resampled, y_resampled = smote.fit_resample(df_cluser.drop(columns=[\"Credits-Y1\", \"BSA\",\"Crd-B1B2\"]),df_cluser[\"Crd-B1B2\"])\n",
    "\n",
    "#     df_cluser_smote = pd.DataFrame(X_resampled)\n",
    "\n",
    "\n",
    "#     df_cluser_smote[\"Crd-B1B2\"] = y_resampled\n",
    "    \n",
    "#     passed_course_columns = [col for col in df_cluser_smote.columns if col.endswith(\"PassedCourse\")]\n",
    "\n",
    "#     passed_course_df = df_cluser_smote[passed_course_columns]\n",
    "\n",
    "#     df_cluser_smote[\"Credits-Y1\"] = passed_course_df.sum(axis=1) * 6\n",
    "#     df_cluser_smote[\"BSA\"] = df_cluser_smote[\"Credits-Y1\"] >= 42#y_resampled\n",
    "#     df_cluser_smote = df_cluser_smote.astype(int)\n",
    "#     return df_cluser_smote\n",
    "\n",
    "\n",
    "\n",
    "# def SmoteSmart(df_cluser):\n",
    "#     df_temp = df_cluser[(df_cluser['Crd-B1B2'] >= 6) & (df_cluser['Crd-B1B2'] <= 18)]\n",
    "\n",
    "\n",
    "\n",
    "#     plt.rcParams[\"figure.figsize\"] = (6,6)\n",
    "#     unique_elements, count_elements = np.unique(df_temp[\"BSA\"], return_counts=True)\n",
    "#     fig1,ax1 = plt.subplots()\n",
    "#     ax1.pie(count_elements,labels=unique_elements, autopct = \"%1.1f%%\", startangle=90,textprops={\"fontsize\":18})\n",
    "\n",
    "\n",
    "\n",
    "#     smote = SMOTE()\n",
    "\n",
    "#     X_resampled, y_resampled = smote.fit_resample(df_temp.drop(columns=[\"Credits-Y1\", \"BSA\"]),df_temp[\"BSA\"])\n",
    "\n",
    "#     df_cluser_smote = pd.DataFrame(X_resampled)\n",
    "#     #df_resampled_clustering[\"Credits-Y1\"] = y_resampled\n",
    "#     df_cluser_smote[\"BSA\"] = y_resampled#df_resampled_clustering[\"Credits-Y1\"] >= 42\n",
    "#     df_cluser_smote = df_cluser_smote.astype(int)\n",
    "\n",
    "\n",
    "\n",
    "#     df_cluser_smote_smart = pd.concat([\n",
    "#         df_cluser,\n",
    "#         df_cluser_smote,\n",
    "#         ],ignore_index=True)\n",
    "    \n",
    "    \n",
    "#     return df_cluser_smote_smart\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftestlist = [4,\n",
    "1,\n",
    "2,\n",
    "3,\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(\"Test.xlsx\",engine=\"xlsxwriter\")\n",
    "writer_Pred = pd.ExcelWriter(\"Predict.xlsx\",engine=\"xlsxwriter\")\n",
    "df_modeleval = pd.DataFrame(columns=[\"Program\",\"Preprocessing\",\"Model\",\"Smote\",\"Filter\",\"Accuracy\",\"Precision\",\"Recall\",\"F1_score\"])\n",
    "\n",
    "\n",
    "for i in dftestlist:\n",
    "    df_test, df2324 = run(i)\n",
    "    round_columns = [\"OverAll\",\t\"B1B2\",\t\"TheRest\"]\n",
    "\n",
    "    for col in round_columns:\n",
    "        df_test[col] = df_test[col].apply(lambda x: round(x,2))\n",
    "        \n",
    "    for col in round_columns:\n",
    "        df2324[col] = df2324[col].apply(lambda x: round(x,2))\n",
    "\n",
    "\n",
    "    hash_columns = [col for col in df_test.columns if col.startswith(\"#\")]\n",
    "    \n",
    "    roelresultaten = pd.read_excel(f'Z:/RLust/Data/MAARTEN 2.0.xlsx', sheet_name=i-1)\n",
    "\n",
    "    df_test[\"#@Roel\"] = roelresultaten[f\"binary_predict\"].dropna().astype(int)\n",
    "    df_test.to_excel(writer, sheet_name=f\"Program{i}\",index=False)\n",
    "\n",
    "    df2324.to_excel(writer_Pred, sheet_name=f\"Program{i}\",index=False)\n",
    "\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets[f\"Program{i}\"]\n",
    "\n",
    "    green_format = workbook.add_format({\"bg_color\":\"#81d41a\"})\n",
    "    Red_format = workbook.add_format({\"bg_color\":\"#c7785d\"})\n",
    "    black_format = workbook.add_format({\"bg_color\":\"#000000\"})\n",
    "\n",
    "    for col_num, col_name in enumerate(df_test.columns,1):  \n",
    "        if col_name.startswith(\"#\"): #or col_name ==\"BSA_Compare\"\n",
    "            for row_num, value in enumerate(df_test[col_name],1):\n",
    "                if value == -1:\n",
    "                    worksheet.write(row_num,col_num-1,\"\",black_format)\n",
    "                elif value == df_test[\"BSA_Compare\"][row_num-1]:\n",
    "                    worksheet.write(row_num,col_num-1,value,green_format)\n",
    "                else:\n",
    "                    worksheet.write(row_num,col_num-1,value,Red_format)\n",
    "\n",
    "\n",
    "\n",
    "    dfTestList = []\n",
    "    dfTestList.append(df_test)\n",
    "    dfTestList.append(df_test[(df_test[\"Crd-B1B2\"] == 12)])\n",
    "    dfTestList.append(df_test[(df_test[\"BSA\"] != \"DI\") & (df_test[\"BSA\"] != \"STGA\")])\n",
    "    dfTestList.append(df_test[(df_test[\"Crd-B1B2\"] == 12) & (df_test[\"BSA\"] != \"DI\") & (df_test[\"BSA\"] != \"STGA\")])\n",
    "\n",
    "    dfTestList_Names = [\"ALL\", \"B1B2-12EC\",\"NO_DI_STGA\",\"NO_DI_STGA-B1B2-12EC\"]\n",
    "\n",
    "    combined = list(zip(dfTestList_Names,dfTestList))\n",
    "\n",
    "\n",
    "\n",
    "    #Sheet model eval\n",
    "    for col in df_test.columns[df_test.columns.get_loc(\"BSA_Compare\") +1:]:\n",
    "\n",
    "        for _name, _df in combined:\n",
    "\n",
    "            model_name = col\n",
    "            pred_labels = df_test.loc[_df.index][col]\n",
    "            true_labels = df_test.loc[_df.index][\"BSA_Compare\"]\n",
    "            \n",
    "            filtered_lists = [(x,y) for x,y in zip(pred_labels,true_labels) if x != -1]\n",
    "\n",
    "            pred_labels,true_labels = zip(*filtered_lists)\n",
    "\n",
    "            split_lst = model_name.split(\"_\")\n",
    "\n",
    "            if model_name == \"#Default\":\n",
    "                split_lst= [\"\",\"Default\",\"\"]\n",
    "\n",
    "            if model_name == \"#@Roel\":\n",
    "                split_lst= [\"@Roel\",\"LRegression\",\"False\"]\n",
    "\n",
    "            new_entries = {\n",
    "                \"Program\": f\"Program{i}\",\n",
    "                \"Preprocessing\":split_lst[0],\n",
    "                \"Model\":split_lst[1],\n",
    "                \"Smote\":split_lst[2],\n",
    "                \"Filter\":_name,     \n",
    "                \"Accuracy\":round(accuracy_score(true_labels, pred_labels),5) ,\n",
    "                \"Precision\":round(precision_score(true_labels, pred_labels),5) ,\n",
    "                \"Recall\":round(recall_score(true_labels, pred_labels),5),\n",
    "                \"F1_score\": round(f1_score(true_labels, pred_labels),5)}\n",
    "\n",
    "            df_modeleval = pd.concat([df_modeleval,pd.DataFrame([new_entries])], ignore_index=True)\n",
    "\n",
    "\n",
    "df_modeleval.to_excel(writer, sheet_name=\"ModelEval\",index=False)\n",
    "\n",
    "\n",
    "writer.close()\n",
    "\n",
    "writer_Pred.close()\n",
    "\n",
    "# cell_range = f\"{chr(64+ col_num)}2:{chr(64+ col_num)}{len(df_test)+1}\"\n",
    "\n",
    "# color_scale_format ={\n",
    "#     \"type\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_Pred.close()\n",
    "\n",
    "\n",
    "# df_test.loc[df_test[col] != df_test[\"BSA_Compare\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
