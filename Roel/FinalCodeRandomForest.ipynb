{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MkHQpJH2VaU"
      },
      "outputs": [],
      "source": [
        "#import pandas etc\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoCiUnTd0OoW",
        "outputId": "edc40c83-2e60-469c-c215-9c776ce6c270"
      },
      "outputs": [],
      "source": [
        "#load data\n",
        "\n",
        "file_path = '...'\n",
        "sheet_name = 2  # Specify the sheet name here\n",
        "#0 for program 1, 1 for program 2 etc\n",
        "df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
        "\n",
        "\n",
        "def extract_course_columns(df):\n",
        "    course_columns = [col for col in df.columns if col.startswith('Course')]\n",
        "    first_try_columns = [col for col in course_columns if col.endswith('-1')]\n",
        "    resit_columns = [col for col in course_columns if col.endswith('-R')]\n",
        "    final_grade_columns = [col for col in course_columns if not (col.endswith('-1') or col.endswith('-R'))]\n",
        "\n",
        "    return first_try_columns, resit_columns, final_grade_columns\n",
        "\n",
        "# Extract course columns\n",
        "first_try_columns, resit_columns, final_grade_columns = extract_course_columns(df)\n",
        "\n",
        "print(\"First Try Columns:\", first_try_columns)\n",
        "print(\"Resit Columns:\", resit_columns)\n",
        "print(\"Final Grade Columns:\", final_grade_columns)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJjDLdgK4VQ-"
      },
      "outputs": [],
      "source": [
        "# Create resits_needed column and initialize with zeros\n",
        "df['resits_needed'] = 0\n",
        "\n",
        "# Loop through each column in first_try_columns\n",
        "for col in first_try_columns:\n",
        "    # Increment resits_needed by 1 if the column value is less than 5.5 or missing\n",
        "    df.loc[(df[col] < 5.5) | (df[col].isna()), 'resits_needed'] += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyNOyWBl7z1I",
        "outputId": "efaf8017-b913-4cd5-fe86-ac50554052f5"
      },
      "outputs": [],
      "source": [
        "# Initialize an empty list to store column names\n",
        "block1and2_results = []\n",
        "\n",
        "# Iterate through each column in first_try_columns\n",
        "for col in first_try_columns:\n",
        "    # Extract the course number X from the column name\n",
        "    course_num = col.split('-')[0]\n",
        "\n",
        "    # Add the initial attempt column (CourseX-1)\n",
        "    block1and2_results.append(col)\n",
        "\n",
        "    # Check if there's a corresponding resit column (CourseX-R)\n",
        "    resit_col = f\"{course_num}-R\"\n",
        "    if resit_col in resit_columns:\n",
        "        # Add the resit column to the list\n",
        "        block1and2_results.append(resit_col)\n",
        "\n",
        "# Print the resulting list of column names\n",
        "print(\"block1and2_results:\", block1and2_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IblDUWBy73Ir"
      },
      "outputs": [],
      "source": [
        "# Initialize the 'absent' column with zeros\n",
        "df['absent'] = 0\n",
        "\n",
        "# Iterate through each column in block1and2_results\n",
        "for col in block1and2_results:\n",
        "    # Extract the course number X from the column name\n",
        "    course_num = col.split('-')[0]\n",
        "\n",
        "    # Check if it's an initial attempt column\n",
        "    if col.endswith('-1'):\n",
        "        # Increment 'absent' by 1 if the initial attempt column is missing\n",
        "        df.loc[df[col].isna(), 'absent'] += 1\n",
        "    elif col.endswith('-R'):\n",
        "        # Check if there's a corresponding initial attempt column and increment 'absent' accordingly\n",
        "        initial_col = f\"{course_num}-1\"\n",
        "        df.loc[(df[col].isna()) & ((df[initial_col] < 5.5) | df[initial_col].isna()), 'absent'] += 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvUv62BR73C0"
      },
      "outputs": [],
      "source": [
        "column_names = block1and2_results\n",
        "means = {}\n",
        "for column in column_names:\n",
        "    means[column] = df[column].mean()\n",
        "\n",
        "mean_programB1B2 = sum(means.values())/ len(means)\n",
        "mean_programB1B2 = round(mean_programB1B2, 2)\n",
        "\n",
        "df['average_gradeB1B2'] = df[block1and2_results].mean(axis=1)\n",
        "df['average_gradeB1B2'] = round(df['average_gradeB1B2'], 2)\n",
        "\n",
        "df['deviationB1B2'] = df['average_gradeB1B2'] - mean_programB1B2\n",
        "df['deviationB1B2'] = round(df['deviationB1B2'], 2)\n",
        "\n",
        "for column, mean in means.items():\n",
        "    print(f'Mean for {column}: {round(mean, 2)}')\n",
        "\n",
        "print('Mean for Program B1B2:', mean_programB1B2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXxeiFc4AMUR"
      },
      "outputs": [],
      "source": [
        "# Create 'Dutch' column with True/False values based on the condition\n",
        "df['Dutch'] = (df['Nationality'] == 'Nederland')\n",
        "\n",
        "\n",
        "df['Dutch'] = df['Dutch'].astype(int)\n",
        "\n",
        "# Create 'Dutch' column with True/False values based on the condition\n",
        "df['Non-Dutch'] = (df['Nationality'] != 'Nederland')\n",
        "\n",
        "\n",
        "df['Non-Dutch'] = df['Non-Dutch'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDdB_ZjHAXGh"
      },
      "outputs": [],
      "source": [
        "# Iterate through block1and2_results to create passed columns\n",
        "for col in block1and2_results:\n",
        "    # Extract the course number and attempt type from the column name\n",
        "    course_num, attempt_type = col.split('-')\n",
        "\n",
        "    # Check if it's an initial attempt column\n",
        "    if attempt_type == '1':\n",
        "        # Create the passed column if it doesn't exist\n",
        "        if f'passed{course_num}' not in df.columns:\n",
        "            df[f'passed{course_num}'] = 0\n",
        "\n",
        "        # Set passed column to 1 if the grade is greater than or equal to 5.5\n",
        "        df.loc[df[col] >= 5.5, f'passed{course_num}'] = 1\n",
        "\n",
        "    # Check if it's a resit attempt column\n",
        "    elif attempt_type == 'R':\n",
        "        # Set passed column to 1 if the resit attempt is greater than or equal to 5.5\n",
        "        df.loc[df[col] >= 5.5, f'passed{course_num}'] = 1\n",
        "\n",
        "        # Set passed column to 1 if the resit attempt is missing and the initial attempt is greater than or equal to 5.5\n",
        "        initial_col = next((c for c in block1and2_results if c.startswith(f'Course{course_num}-1')), None)\n",
        "        if initial_col:\n",
        "            df.loc[(df[col].isna()) & (df[initial_col] >= 5.5), f'passed{course_num}'] = 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHj188R8CxQ1"
      },
      "outputs": [],
      "source": [
        "# Initialize the YEAR column with zeros\n",
        "df['YEAR'] = 0\n",
        "\n",
        "# Loop through each column specified in the final_grade_columns list\n",
        "for var in final_grade_columns:\n",
        "    df['YEAR'] += df[var].apply(lambda x: 6 if x >= 5.5 and not pd.isnull(x) else 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHyZdDDeCxOJ"
      },
      "outputs": [],
      "source": [
        "# Generate the passed42 column and convert boolean to integer\n",
        "df['passed42'] = (df['YEAR'] >= 42).astype(int)\n",
        "df['passed36'] = (df['YEAR'] >= 36).astype(int)\n",
        "df['passed48'] = (df['YEAR'] >= 48).astype(int)\n",
        "\n",
        "\n",
        "df = pd.get_dummies(df, columns=['Gender', 'PreEducation'], dtype=int)\n",
        "\n",
        "\n",
        "non_categorical_columns = [col for col in df.columns if col not in ['Gender', 'Nationality', 'PreEducation', 'Program', 'Year', 'BSA']]\n",
        "df[non_categorical_columns] = df[non_categorical_columns].fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cO_eNrhED8eh"
      },
      "outputs": [],
      "source": [
        "#drop columns not in blocks 1 and 2\n",
        "columns_to_drop = [ 'Credits-Y1', 'BSA','Program', 'YEAR', 'Year', 'Nationality']\n",
        "\n",
        "\n",
        "\n",
        "# Drop the specified columns\n",
        "df.drop(columns=columns_to_drop, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5f6Dtx4ND8be"
      },
      "outputs": [],
      "source": [
        "# Drop the columns specified in final_grade_columns\n",
        "df.drop(columns=final_grade_columns, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YMtvqTZD8Yh"
      },
      "outputs": [],
      "source": [
        "#load train and test data\n",
        "train_file_path = '...'\n",
        "test_file_path = '...'\n",
        "\n",
        "train_df = pd.read_excel(train_file_path, sheet_name=sheet_name)\n",
        "test_df = pd.read_excel(test_file_path, sheet_name=sheet_name)\n",
        "\n",
        "\n",
        "train_indices = df[\"train\"].isin(train_df[\"train\"])\n",
        "test_indices = df[\"train\"].isin(test_df[\"train\"])\n",
        "\n",
        "X = df.drop(columns = ['passed36','passed42','passed48'])\n",
        "y = df['passed42']\n",
        "\n",
        "X_train = X.loc[train_indices].drop(columns=[\"train\"])\n",
        "y_train = y.loc[train_indices]\n",
        "\n",
        "X_test = X.loc[test_indices].drop(columns=[\"train\"])\n",
        "y_test = y.loc[test_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUTVGwGaD8R6",
        "outputId": "54f8145d-321c-454c-c466-9db900977cc3"
      },
      "outputs": [],
      "source": [
        "# Create a baseline Random Forest Classifier\n",
        "baseline_rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the baseline model\n",
        "baseline_rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_baseline = baseline_rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the baseline model\n",
        "accuracy_baseline = accuracy_score(y_test, y_pred_baseline)\n",
        "precision_baseline = precision_score(y_test, y_pred_baseline, average='binary')\n",
        "recall_baseline = recall_score(y_test, y_pred_baseline, average='binary')\n",
        "f1_baseline = f1_score(y_test, y_pred_baseline, average='binary')\n",
        "\n",
        "# Print the baseline metrics\n",
        "print('Baseline Model Performance:')\n",
        "print(f'Accuracy: {accuracy_baseline}')\n",
        "print(f'Precision: {precision_baseline}')\n",
        "print(f'Recall: {recall_baseline}')\n",
        "print(f'F1 Score: {f1_baseline}')\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_test, y_pred_baseline))\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test, y_pred_baseline))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf1UApdwFb0K",
        "outputId": "58393fea-0fbe-408f-cfa4-1a3eb49f2028"
      },
      "outputs": [],
      "source": [
        "# Define the parameter grid for Grid Search\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42), param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "\n",
        "# Fit the grid search to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters found by Grid Search\n",
        "print(f'Best parameters found: {grid_search.best_params_}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SkKG-yeFbxg",
        "outputId": "3d90de71-3fa1-435a-d9d6-4e57016609d4"
      },
      "outputs": [],
      "source": [
        "# Create the model with the best parameters found by Grid Search\n",
        "best_rf_classifier = RandomForestClassifier(\n",
        "    max_depth=grid_search.best_params_['max_depth'],\n",
        "    max_features=grid_search.best_params_['max_features'],\n",
        "    min_samples_leaf=grid_search.best_params_['min_samples_leaf'],\n",
        "    min_samples_split=grid_search.best_params_['min_samples_split'],\n",
        "    n_estimators=grid_search.best_params_['n_estimators'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model with the best parameters\n",
        "best_rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set with the best model\n",
        "y_pred_best = best_rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model with the best parameters\n",
        "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
        "precision_best = precision_score(y_test, y_pred_best, average='binary')\n",
        "recall_best = recall_score(y_test, y_pred_best, average='binary')\n",
        "f1_best = f1_score(y_test, y_pred_best, average='binary')\n",
        "\n",
        "# Print the metrics for the best model\n",
        "print('Best Model Performance:')\n",
        "print(f'Accuracy: {accuracy_best}')\n",
        "print(f'Precision: {precision_best}')\n",
        "print(f'Recall: {recall_best}')\n",
        "print(f'F1 Score: {f1_best}')\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_test, y_pred_best))\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test, y_pred_best))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNkh2M8EFbr5",
        "outputId": "cfa96a03-2eff-4518-bbf7-d1b0bf94f189"
      },
      "outputs": [],
      "source": [
        "# Print the predictions made by the best model\n",
        "print(\"Best Model Predictions:\")\n",
        "print(y_pred_best)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdPl-klsFbpV",
        "outputId": "35b355cc-0305-4e03-bd63-27c00b884028"
      },
      "outputs": [],
      "source": [
        "# Get the feature importances of the best model\n",
        "feature_importances_best = best_rf_classifier.feature_importances_\n",
        "\n",
        "\n",
        "feature_names = X_test.columns\n",
        "\n",
        "# Create a DataFrame for better visualization\n",
        "importance_df_best = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': feature_importances_best\n",
        "})\n",
        "\n",
        "# Sort the DataFrame by importance\n",
        "importance_df_best = importance_df_best.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Display the DataFrame\n",
        "print('Feature Importances of the Best Model:')\n",
        "print(importance_df_best)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "IW1xCx57Fbmd",
        "outputId": "2714c1a0-81e3-40c5-df36-28e4092d4835"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=importance_df_best)\n",
        "plt.title('Feature Importances of the Best Model')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoK1wavMFbjw",
        "outputId": "854e0969-df1c-4f4b-e519-ce5d7392120d"
      },
      "outputs": [],
      "source": [
        "correlation_matrix = X_train.corr()\n",
        "\n",
        "print(correlation_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "RD5VNLJOFbg9",
        "outputId": "ef49ef03-af9c-471c-8bcc-8e80d8745b41"
      },
      "outputs": [],
      "source": [
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_best)\n",
        "\n",
        "# Plot the confusion matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', cbar=False)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_score = accuracy_best + recall_best + precision_best + f1_best\n",
        "print(\"Total score\", round(total_score, 2))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
